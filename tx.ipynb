{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import operator\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the list of columns or extracting features\n",
    "path ='20_newsgroups'                # download dataset from https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups\n",
    "documents =[]       # an array of tuples of words and category\n",
    "for foldername in os.listdir(path):\n",
    "    for filename in os.listdir(path+'\\\\'+foldername):\n",
    "        with open((path+'\\\\'+foldername+'\\\\'+filename),'r') as f:\n",
    "            text = f.read()\n",
    "        # splitting the text by non character using regression\n",
    "        words = re.split(r'\\W+',text)\n",
    "        output_words = []   # an array of clean words\n",
    "        for w in words:\n",
    "            if len(w) <= 3:     # ignoring words having length less than 4\n",
    "                continue\n",
    "            if w.lower() not in stop_words:\n",
    "                output_words.append(w.lower())\n",
    "        documents.append((output_words,foldername))   # appending cleaned words of doc with category of doc\n",
    "        \n",
    "random.shuffle(documents)    # shuffling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "training_documents = documents[:14000]\n",
    "testing_documents = documents[14000:]\n",
    "\n",
    "# building feature list\n",
    "all_words = []           # an array of all words in training_documents\n",
    "for doc in training_documents:\n",
    "    all_words += doc[0]        \n",
    "\n",
    "dictionary = {}      # for storing frequency of all_words\n",
    "for word in all_words:         \n",
    "    if word in dictionary:\n",
    "        dictionary[word] += 1\n",
    "    else:\n",
    "        dictionary[word] = 1\n",
    "        \n",
    "# sorting the dictionary in deceasing order so that top 2000 words can be chosen\n",
    "sorted_d = sorted(dictionary.items(), key=operator.itemgetter(1),reverse=True)     \n",
    "\n",
    "feature_list=[]   # list of words/ vocabulary that will be the column of x        \n",
    "for d in sorted_d[:2000]:    # choosing top 2000 words \n",
    "    feature_list.append(d[0])      # and only inserting words/vocab not the count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(documents):\n",
    "    x = pd.DataFrame(data=np.zeros((len(documents),2000),dtype=int),columns=feature_list)\n",
    "    y = []      # for y dataset\n",
    "    i=-1       # for row index\n",
    "    for document,category in documents:     # for every document\n",
    "        i = i+1\n",
    "        y.append(category)       # appending category\n",
    "        for word in document:\n",
    "            if word in feature_list:  # if word is in feature_list \n",
    "                x.loc[i,word] += 1           # increase count for that doc in x dataset for respective document/ row                  \n",
    "    y = np.array(y) # converting from list to np array\n",
    "    y = y.reshape(-1,)    # reshaping\n",
    "    x = x.iloc[:].values   # taking x values\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building dataset\n",
    "x_train,y_train = get_dataset(training_documents)  \n",
    "x_test,y_test = get_dataset(testing_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification using sklearn Multinomial naive bayes\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train,y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing using own naive bayes for text classification\n",
    "def fit(X_train, Y_train):\n",
    "    result = {}\n",
    "    class_values = set(Y_train)   # classes of Y_train\n",
    "    \n",
    "    result[\"total_data\"] = len(Y_train)   # no. of times all classes in Y_train\n",
    "    for current_class in class_values:\n",
    "        result[current_class] = {}       # for each feature will hold count words in current_class\n",
    "        result[current_class][\"total_count\"] = 0   # total count of words in current_class\n",
    "        \n",
    "        current_class_rows = (Y_train == current_class)\n",
    "        X_train_current = X_train[current_class_rows] # X_train having current_class\n",
    "        Y_train_current = Y_train[current_class_rows] # Y_train having current_class\n",
    "        result[current_class]['total_time_class']= len(Y_train_current)  # no. of times current_class in Y_train\n",
    "        num_features = X_train.shape[1]   # total columns/features\n",
    "        \n",
    "        for j in range(0, num_features ):      # for every word\n",
    "            result[current_class][j] = X_train_current[:,j].sum()   # count of words in current_class\n",
    "            result[current_class][\"total_count\"] += result[current_class][j]         \n",
    "    #print(result)      \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary, x, current_class):\n",
    "    output = np.log(dictionary[current_class][\"total_time_class\"]) - np.log(dictionary[\"total_data\"])  # probability of y in current_class     \n",
    "    num_features = len(dictionary[current_class].keys())-2   # -2 due to 'total_count' and 'total_time_class'  \n",
    "    for j in range(0, num_features):  # for every feature/column\n",
    "        if x[j] == 0:       # if x in testing data ... for current column is zero ..then skip that x column\n",
    "            continue\n",
    "        count_xj_within_current_class = dictionary[current_class][j] + 1         \n",
    "        count_current_class = dictionary[current_class][\"total_count\"] + (len(dictionary[current_class].keys())-2)   # plus number of words in vocab         \n",
    "        current_xj_probablity = np.log(count_xj_within_current_class) - np.log(count_current_class)            \n",
    "        output = output + current_xj_probablity\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(dictionary, x):\n",
    "    classes = dictionary.keys()    # list of all features  .. also have 'total_data' will ignore this      a\n",
    "    best_p = -1000         # best probability \n",
    "    best_class = -1        # best y class having best probability \n",
    "    first_run = True        \n",
    "    for current_class in classes:\n",
    "        if (current_class == \"total_data\"):\n",
    "            continue\n",
    "        p_current_class = probability(dictionary, x, current_class)\n",
    "        if (first_run or p_current_class > best_p):\n",
    "            best_p = p_current_class\n",
    "            best_class = current_class\n",
    "        first_run = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary, X_test):\n",
    "    y_pred = []\n",
    "    for x in X_test:       # for every row in X_test\n",
    "        x_class = predictSinglePoint(dictionary, x)    #return predicted class of y   \n",
    "        y_pred.append(x_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = fit(x_train,y_train)\n",
    "y_predict = predict(dictionary,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoreboard of text classification\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score using inbuilt implemented naive bayes in skearn->  0.835917958979\nScore using own implemented naive bayes->  0.832749708187\n"
     ]
    }
   ],
   "source": [
    "print('Scoreboard of text classification\\n')\n",
    "print('Score using inbuilt implemented naive bayes in skearn-> ',clf.score(x_test,y_test))\n",
    "print('Score using own implemented naive bayes-> ',np.mean(y_predict==y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[234   0   0   0   0   0   0   3   3   1   0   0   1   1   1   5   0   1\n    0  55]\n [  0 187  33  11  16  18   6   2   2   2   0   2  11   2   4   0   0   0\n    0   0]\n [  0   1 267  18   2  10   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0]\n [  0   3  19 195  68   2   9   0   0   0   0   2  11   0   0   0   0   0\n    0   0]\n [  0   1  10  40 224   1   7   0   2   0   0   0   6   0   2   0   0   0\n    0   0]\n [  0  15  40   5   3 233   2   0   1   0   0   0   3   2   0   0   0   0\n    0   0]\n [  0   0   1   3   1   1 263   6   1   0   1   0   2   0   1   0   0   0\n    0   0]\n [  0   0   0   1   0   0   6 296  10   0   0   0  10   0   1   1   2   0\n    3   0]\n [  0   0   0   0   0   0   8   9 275   1   0   0   2   0   0   1   0   0\n    0   0]\n [  0   0   0   1   0   0   2   5   1 287  13   0   0   0   1   1   0   0\n    0   0]\n [  0   0   0   0   0   0   1   2   0   6 281   0   0   1   1   0   0   0\n    0   0]\n [  1   1   0   0   1   0   1   0   2   0   0 278   1   1   1   0   5   0\n    0   1]\n [  0   1   2   5  10   0   8  11   0   0   2   0 253   4   3   0   0   0\n    0   0]\n [  0   3   3   1   3   0   3   8  19   2   0   2  13 215   0   0   0   0\n    1   1]\n [  0   5   1   0   0   1   1   2   1   3   0   0   7   2 276   0   1   0\n    2   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 294   0   1\n    0   0]\n [  0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0 284   1\n   10   8]\n [  0   1   0   0   0   0   5   0   0   0   0   1   2   0   0   0   3 274\n   14   1]\n [  1   0   0   0   0   0   1   0   0   1   0   1   1   2   1   1  42  12\n  212  32]\n [ 61   1   0   0   0   0   0   0   0   0   0   0   0   2   0  14  17   1\n   26 185]]\n-------------------------------\n                          precision    recall  f1-score   support\n\n             alt.atheism       0.79      0.77      0.78       305\n           comp.graphics       0.85      0.63      0.73       296\n comp.os.ms-windows.misc       0.71      0.90      0.79       298\ncomp.sys.ibm.pc.hardware       0.70      0.63      0.66       309\n   comp.sys.mac.hardware       0.68      0.76      0.72       293\n          comp.windows.x       0.88      0.77      0.82       304\n            misc.forsale       0.81      0.94      0.87       280\n               rec.autos       0.86      0.90      0.88       330\n         rec.motorcycles       0.86      0.93      0.90       296\n      rec.sport.baseball       0.95      0.92      0.93       311\n        rec.sport.hockey       0.95      0.96      0.95       292\n               sci.crypt       0.97      0.95      0.96       293\n         sci.electronics       0.78      0.85      0.81       299\n                 sci.med       0.93      0.78      0.85       274\n               sci.space       0.94      0.91      0.93       302\n  soc.religion.christian       0.93      1.00      0.96       295\n      talk.politics.guns       0.80      0.93      0.86       305\n   talk.politics.mideast       0.94      0.91      0.93       301\n      talk.politics.misc       0.79      0.69      0.74       307\n      talk.religion.misc       0.65      0.60      0.63       307\n\n             avg / total       0.84      0.84      0.83      5997\n\n"
     ]
    }
   ],
   "source": [
    "# for inbuilt naive bayes\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('-------------------------------')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n\n             alt.atheism       0.75      0.81      0.78       305\n           comp.graphics       0.84      0.60      0.70       296\n comp.os.ms-windows.misc       0.69      0.86      0.76       298\ncomp.sys.ibm.pc.hardware       0.72      0.60      0.66       309\n   comp.sys.mac.hardware       0.65      0.82      0.72       293\n          comp.windows.x       0.89      0.76      0.82       304\n            misc.forsale       0.81      0.94      0.87       280\n               rec.autos       0.90      0.90      0.90       330\n         rec.motorcycles       0.88      0.95      0.92       296\n      rec.sport.baseball       0.95      0.94      0.94       311\n        rec.sport.hockey       0.94      0.95      0.94       292\n               sci.crypt       0.98      0.95      0.96       293\n         sci.electronics       0.76      0.89      0.82       299\n                 sci.med       0.89      0.79      0.84       274\n               sci.space       0.95      0.88      0.92       302\n  soc.religion.christian       0.96      1.00      0.98       295\n      talk.politics.guns       0.76      0.95      0.84       305\n   talk.politics.mideast       0.96      0.90      0.93       301\n      talk.politics.misc       0.78      0.66      0.72       307\n      talk.religion.misc       0.68      0.51      0.59       307\n\n             avg / total       0.84      0.83      0.83      5997\n\n------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[247   2   0   0   0   1   1   2   4   3   0   0   0   3   0   2   0   0\n    0  40]\n [  0 179  42  12  22  13   6   1   0   0   0   2  14   4   1   0   0   0\n    0   0]\n [  0   3 256  19   8  10   1   0   0   0   0   0   0   1   0   0   0   0\n    0   0]\n [  0   3  16 186  84   0   6   1   0   0   0   1  12   0   0   0   0   0\n    0   0]\n [  0   1   5  32 239   2   6   1   0   0   0   0   5   1   1   0   0   0\n    0   0]\n [  0  13  47   2   5 231   1   0   0   0   0   1   1   2   1   0   0   0\n    0   0]\n [  0   0   2   3   2   0 264   6   0   0   0   0   1   1   1   0   0   0\n    0   0]\n [  0   0   0   0   0   0   8 297   8   0   0   0  11   1   0   0   4   0\n    1   0]\n [  0   0   0   0   0   0   7   6 282   0   0   0   0   0   1   0   0   0\n    0   0]\n [  0   0   0   0   0   0   1   1   1 293  15   0   0   0   0   0   0   0\n    0   0]\n [  0   0   0   0   0   0   2   2   1  10 276   0   0   0   0   0   0   0\n    1   0]\n [  0   0   0   0   0   0   1   0   2   0   0 277   5   0   1   0   6   0\n    0   1]\n [  0   2   2   2   4   0   8   8   0   0   2   0 266   4   0   0   1   0\n    0   0]\n [  0   3   1   0   3   1   4   5  20   1   0   1  18 216   0   0   0   0\n    1   0]\n [  1   5   1   1   0   1   3   1   2   2   0   0  12   4 266   1   0   0\n    1   1]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0 294   0   0\n    0   0]\n [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0 291   0\n    9   4]\n [  1   0   0   0   0   0   4   0   0   0   0   0   2   1   0   0   7 272\n   13   1]\n [  1   0   0   0   0   0   2   0   0   1   0   1   0   2   6   0  53  10\n  204  27]\n [ 78   1   0   0   0   0   2   0   0   0   0   0   2   1   0   9  23   2\n   31 158]]\n"
     ]
    }
   ],
   "source": [
    "# for own implemented naive bayes\n",
    "print(classification_report(y_test,y_predict))\n",
    "print('------------------------------')\n",
    "print(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
